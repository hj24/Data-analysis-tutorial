# Chapter 3挖掘建模

## S2.聚类分析

### 简介

- 从实际问题的角度来看，如果我们作为一个餐厅经理，为了提升业绩，我们往往需要根据对用户的消费记录进行测量，进一步评判餐饮客户的价值，将其划分为很多个类别，找到有价值的客户进行定向服务。
- 以上便是聚类分析的实际应用，所谓聚类分析就是在没有给定数据类别的划分的情况下，根据数据相似度进行样本分组的一种方法。
- 聚类分析本质上属于一种无监督的学习方法。常用聚类方法如下：

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fubkucoebuj30ky05z417.jpg)

- 本节主要介绍KMeans聚类，后续有一节实战练习，会介绍其它的聚类的实现

## KMeans聚类算法

- 该算法是典型的基于距离的非层次聚类算法，在最小化误差函数的基础上将数据划分为预定的K类，采用距离作为相似性的评价指标。

1. 算法步骤

   1) 从N个样本数据中随机选取K个对象作为初始的聚类中心。

   2) 分别计算每个样本到各聚类中心的距离，将对象分配到距离最近的聚类中

   3) 所有对象分配完之后，重新计算K个聚类的中心

   4) 与前一次计算得到的K个聚类中心比较，如果聚类中心发生变化则转2) ,否则转入5)

   5) 当质心不发生变化时停止并输出聚类结果

   - 该算法的聚类结果依赖于初始聚类中心的随机选择，可能使结果严重偏离全局最优分类。
   - 实践中为了避免上述问题，通常选择几个不同的聚类中心多次运行KMeans算法，在所有对象分配完成后，重新计算K个聚类中心时，对于连续数据，聚类中心取该簇的均值，但当样本的某些属性是分类变量时，均值可能无定义，可以使用K众数方法。

2. 数据类型与相似性的度量

   这里主要谈一谈连续属性，对于连续属性，要先对各属性进行零-均值规范，再进行距离的计算。在KMeans算法中一般需要度量样本之间的距离，样本与簇之间的距离以及簇与簇之间的距离。

   1. 度量样本之间的相似性最常用的是欧几里得距离，曼哈顿距离和闵可夫斯基距离

   2. 样本与簇之间的距离可以用样本到簇中心的距离d(ei,x)

   3. 簇与簇之间的距离可以用簇中心的距离d(ei,ej)

      用p个属性来表示n个样本的数据矩阵如下：

		](https://ws4.sinaimg.cn/large/0069RVTdgy1fublkqrwnrg303201v0kb.gif)	

			欧几里得距离：

![](https://ws3.sinaimg.cn/large/0069RVTdgy1fublq1r61pg30c300ygld.gif)

​		曼哈顿距离：

![](https://ws4.sinaimg.cn/large/0069RVTdgy1fublwxlfd1g30am00k3y9.gif)	

​		闵可夫斯基距离：

![](https://ws4.sinaimg.cn/large/0069RVTdgy1fubm05slg5g30cy00yjr5.gif)

​		q=1时闵可夫斯基距离等于曼哈顿距离，q=2时等于欧几里得距离

3. 目标函数

   使用误差平方项和SSE作为度量聚类质量的目标函数

   连续属性的SSE计算公式：

   ![](https://ws4.sinaimg.cn/large/0069RVTdgy1fubmm9qtj5g305o01k741.gif)

   簇Ei的聚类中心ei计算公式为：

   ![](https://ws2.sinaimg.cn/large/0069RVTdgy1fubmnmfvm1g302n01c0g5.gif)

   符号说明：

   ![](https://ws1.sinaimg.cn/large/0069RVTdgy1fubmowdbb1j30kp03nab1.jpg)

## 实例分析

- 下面结合实际数据开始分析，数据见consumption_data.xls，是餐饮客户的消费行为特征，部分数据如下：

![](https://ws2.sinaimg.cn/large/0069RVTdgy1fubmtrv9egj307f09m0t4.jpg)

- R为最近一次消费时间间隔，F为消费频率，M为消费总金额
- 采用KMeans聚类算法，设定聚类个数K为3，最大迭代次数为500次，采用欧式距离

1. 聚类分析

   全部代码，下面会逐行分析：**ClusterAnalysis.py**

   ```python
   #!/usr/bin/env python
   # -*- coding: utf-8 -*-
   __author__ = "MambaHJ"
   
   import pandas as pd
   import os
   
   def get_data(data_name=''):
   	current_path = os.getcwd()
   	parent_path = os.path.dirname(current_path)
   	data_dir = os.path.join(parent_path,'data')
   	for f in os.listdir(data_dir):
   		if f.endswith(data_name):
   			data_path = os.path.join(data_dir,f)
   	data = pd.read_excel(data_path,index_col='Id')
   	return data,os.path.dirname(data_path)
   
   def output_file(data,file_path=''):
   	data_dir = os.path.join(file_path,'tmp')
   	output = 'data_type.xls'
   	output = os.path.join(data_dir,output)
   	data.to_excel(output)
   
   def density_plot(data,title):
   	import matplotlib.pyplot as plt
   	plt.figure()
   	# 逐列作图
   	for i in range(len(data.iloc[0])):
   		(data.iloc[:,i]).plot(kind='kde',label=data.columns[i],linewidth=2)
   	plt.ylabel(u'density')
   	plt.xlabel(u'population')
   	plt.title(u'cluster class {} density'.format(title))
   	plt.legend()
   	return plt
   
   def density_plot(data,k):
   	import matplotlib.pyplot as plt
   	p = data.plot(kind='kde',linewidth=2,subplots=True,sharex=False)
   	[p[i].set_ylabel(u'density') for i in range(k)]
   	plt.legend()
   	return plt
   
   def tsne_plot(data_zs,r,show_flag=False):
   	if show_flag:
   		# 使用TSNE进行数据降纬并展示聚类结果
   		from sklearn.manifold import TSNE
   		tsne = TSNE()
   		# 进行降维
   		tsne.fit_transform(data_zs)
   		# 转换数据格式
   		tsne = pd.DataFrame(tsne.embedding_,index=data_zs.index)
   		# 把不同类别用不同颜色和样式绘制
   		import matplotlib.pyplot as plt
   		d = tsne[r[u'聚类类别'] == 0]
   		plt.plot(d[0],d[1],'r.')
   		d = tsne[r[u'聚类类别'] == 1]
   		plt.plot(d[0],d[1],'go')
   		d = tsne[r[u'聚类类别'] == 2]
   		plt.plot(d[0],d[1],'b*')
   		plt.show()
   
   def main():
   	data, data_path= get_data(data_name='consumption_data.xls')
   	print(u'打印数据：\n{}\n数据概况：\n{}'.format(data,data.describe()))
   	# 聚类类别
   	k = 3
   	# 聚类最大循环次数
   	iteration = 500
   	# 数据标准化
   	data_zs = 1.0*(data - data.mean())/data.std()
   	print(u'标准化之后的数据：\n{}\n数据概况：\n{}'.format(data_zs,data_zs.describe()))
   	from sklearn.cluster import KMeans
   	# 分为k类，并发数为4
   	model = KMeans(n_clusters=k,n_jobs=4,max_iter=iteration)
   	# 开始聚类
   	model.fit(data_zs)
   	# 简单打印结果
   	# 统计各个类别数目
   	r_1 = pd.Series(model.labels_).value_counts()
   	# 找出聚类中心
   	r_2 = pd.DataFrame(model.cluster_centers_)
   	# 横向连接(0 是纵向)，得到聚类中心对应类别下的数目
   	r = pd.concat([r_2,r_1],axis=1)
   	# 重命名表头
   	r.columns = list(data.columns)+[u'类别数目']
   	print(u'聚类概况：\n{}'.format(r))
   	# 详细输出原始数据及其类别
   	r = pd.concat([data,pd.Series(model.labels_,index=data.index)],axis=1)
   	r.columns = list(data.columns)+[u'聚类类别']
   	print(u'聚类详情：\n{}'.format(r))
   	# 将聚类结果保存
   	output_file(r,file_path=os.path.dirname(data_path))
   	pic_output = os.path.join(os.path.dirname(data_path),'tmp/pd_')
   	for i in range(k):
   		density_plot(data[r[u'聚类类别'] == i],k=k).savefig(u'{}{}.png'.format(pic_output,i))
   	# 使用TSNE进行数据降纬并展示聚类结果
   	tsne_plot(data_zs,r=r,show_flag=True)
   
   if __name__ == '__main__':
   	main()
   ```

   下面逐行分析一下代码：

   1. 读取数据的接口`get_data()`之前写过很多次，就不介绍了

      ```python
      data, data_path= get_data(data_name='consumption_data.xls')
      ```

   2. 算法的参数配置，以及打印数据概况

      ```python
      print(u'打印数据：\n{}\n数据概况：\n{}'.format(data,data.describe()))
      # 聚类类别
      k = 3
      # 聚类最大循环次数
      iteration = 500
      ```

      运行结果：

      ```
      打印数据：
            R   F        M
      Id                  
      1    27   6   232.61
      2     3   5  1507.11
      3     4  16   817.62
      4     3  11   232.81
      5    14   7  1913.05
      6    19   6   220.07
      7     5   2   615.83
      8    26   2  1059.66
      9    21   9   304.82
      ..   ..  ..      ...
      938  19   4  1163.08
      939   9   7  1007.06
      940  27   7  1322.94
      941  30   4   860.41
      942  22   1   776.70
      
      [940 rows x 3 columns]
      数据概况：
                      R           F            M
      count  940.000000  940.000000   940.000000
      mean    16.747872    9.615957  1061.683436
      std     13.415743    7.325998   715.513381
      min      0.000000    1.000000    23.240000
      25%      8.000000    3.000000   551.615000
      50%     15.000000    7.000000  1031.015000
      75%     23.000000   15.000000  1518.402500
      max    121.000000   32.000000  7795.030000
      ```

   3. 数据预处理，这里只涉及标准化

      ```python
      # 数据标准化
      data_zs = 1.0*(data - data.mean())/data.std()
      print(u'标准化之后的数据：\n{}\n数据概况：\n{}'.format(data_zs,data_zs.describe()))
      ```

      运行结果：

      ```
      标准化之后的数据：
                  R         F         M
      Id                               
      1    0.764186 -0.493579 -1.158711
      2   -1.024757 -0.630079  0.622527
      3   -0.950217  0.871423 -0.341103
      4   -1.024757  0.188922 -1.158432
      5   -0.204824 -0.357079  1.189868
      6    0.167872 -0.493579 -1.176237
      7   -0.875678 -1.039580 -0.623124
      8    0.689647 -1.039580 -0.002828
      9    0.316951 -0.084078 -1.057791
      ..        ...       ...       ...
      934 -1.173835  2.372925  0.731526
      935  0.018793  2.372925  9.410511
      936 -1.099296  1.007923  1.789270
      937 -1.173835 -0.630079  1.123804
      938  0.167872 -0.766579  0.141712
      939 -0.577521 -0.357079 -0.076342
      940  0.764186 -0.357079  0.365132
      941  0.987804 -0.766579 -0.281299
      942  0.391490 -1.176080 -0.398292
      
      [940 rows x 3 columns]
      数据概况：
                        R             F             M
      count  9.400000e+02  9.400000e+02  9.400000e+02
      mean   1.086601e-16  9.070758e-17  1.432424e-15
      std    1.000000e+00  1.000000e+00  1.000000e+00
      min   -1.248375e+00 -1.176080e+00 -1.451326e+00
      25%   -6.520602e-01 -9.030794e-01 -7.128706e-01
      50%   -1.302852e-01 -3.570786e-01 -4.286214e-02
      75%    4.660292e-01  7.349228e-01  6.383096e-01
      max    7.770880e+00  3.055426e+00  9.410511e+00
      ```

   4. 聚类模型训练，此步骤大概需要20几秒

      ```python
      from sklearn.cluster import KMeans
      # 分为k类，并发数为4
      model = KMeans(n_clusters=k,n_jobs=4,max_iter=iteration)
      # 开始聚类
      model.fit(data_zs)
      ```

   5. 打印结果，并将结果数据进行一些处理

      - 根据model.labels_取出聚类类别

        ```python
        # 统计各个类别数目
        r_1 = pd.Series(model.labels_).value_counts()
        ```

      - **pd.Series对象是一种类似于一维数组的对象，是由一组数据及其所对应的标签所组成**

      - 根据model.cluster_centers_取出聚类中心

        ```python
        # 找出聚类中心
        r_2 = pd.DataFrame(model.cluster_centers_)
        ```

      - **DataFrame 是pandas最常用的数据结构，类似于数据库中的表，不过DataFrame不仅仅限制于2维，可以创建多维数据表。DataFrame既有行索引，也有列索引，可以看做是Series组成的字典，每个Series看做DataFrame的一个列。**

      - 重新制作聚类后的表格并初步打印聚类结果，给取出的类别标签加一个类别数目的表头

        ```python
        # 横向连接(0 是纵向)，得到聚类中心对应类别下的数目
        r = pd.concat([r_2,r_1],axis=1)
        # 重命名表头
        r.columns = list(data.columns)+[u'类别数目']
        print(u'聚类概况：\n{}'.format(r))
        ```

        运行结果:

        ```
        聚类概况：
                  R         F         M  类别数目
        0 -0.162951  1.116722  0.395575   340
        1  3.455055 -0.295654  0.449123    40
        2 -0.147855 -0.656892 -0.272251   560
        ```

      - pd.concat()连接两个表格

      - 打印详细数据及其类别

        ```python
        # 详细输出原始数据及其类别
        r = pd.concat([data,pd.Series(model.labels_,index=data.index)],axis=1)
        r.columns = list(data.columns)+[u'聚类类别']
        print(u'聚类详情：\n{}'.format(r))
        # 将聚类结果保存
        output_file(r,file_path=os.path.dirname(data_path))
        ```

      - 注意这一连接的是原始数据data，data的行数和Series对象，data_zs是相同的，所以可以用data的index为表格命名

        运行结果：

        ```
        聚类详情：
              R   F        M  聚类类别
        Id                        
        1    27   6   232.61     2
        2     3   5  1507.11     2
        3     4  16   817.62     0
        4     3  11   232.81     2
        5    14   7  1913.05     2
        6    19   6   220.07     2
        7     5   2   615.83     2
        8    26   2  1059.66     2
        9    21   9   304.82     2
        ..   ..  ..      ...   ...
        932  17  26  1292.21     0
        933  16   7  1801.38     2
        934   1  27  1585.10     0
        935  17  27  7795.03     0
        936   2  17  2341.93     0
        937   1   5  1865.78     2
        938  19   4  1163.08     2
        939   9   7  1007.06     2
        940  27   7  1322.94     2
        941  30   4   860.41     2
        942  22   1   776.70     2
        
        [940 rows x 4 columns]
        ```

   6. 可视化部分

      **绘制聚类的概率密度**

      ```python
      def density_plot(data,k):
      	import matplotlib.pyplot as plt
      	p = data.plot(kind='kde',linewidth=2,subplots=True,sharex=False)
      	[p[i].set_ylabel(u'density') for i in range(k)]
      	plt.legend()
      	return plt
      ```

      - kind='kde'是绘制密度图，该接口结束数据和聚类类数k，分别为每类绘制密度图

      - `[p[i].set_ylabel(u'density') for i in range(k)]`是列表生成式，分别为每一类的y轴设置标签，如果这个不熟的话可以用循环代替

        ```python
        for i in range(k):
        	p[i].set_ylabel(u'density')
        ```

      保存图片

      ```python
      pic_output = os.path.join(os.path.dirname(data_path),'tmp/pd_')
      for i in range(k):
      	density_plot(data[r[u'聚类类别'] == i],k=k).savefig(u'{}	{}.png'.format(pic_output,i))
      ```

      - 我们之前用r保存聚类后的表格，最后一列是各数据对应的类别，这里我们用它和i对比判断，将属于i类的数据传入绘图接口

      图片：

      ![](https://ws2.sinaimg.cn/large/0069RVTdgy1fubogqqs3ij30hs0dcaau.jpg)

   ![](https://ws2.sinaimg.cn/large/0069RVTdgy1fubogqgze7j30hs0dcjs5.jpg)

   ![](https://ws2.sinaimg.cn/large/0069RVTdgy1fubogq71uhj30hs0dcq3m.jpg)

   分析：

   第一类，R即最近一次消费间隔时间较大主要集中在25-100天，消费次数集中在0-15次，消费金额集中在0-2000

   第二类，最近一次消费时间间隔在0-30之间，消费次数集中在0-12次，消费金额集中在100-2000

   第三类，最近一次消费时间间隔在0-30之间，消费次数集中在10-25次，消费金额集中在0-1800

   初步可以得出，该店的主力顾客在第二类，菜单应注意迎合他们的口味，兼顾其他两类。

   **用TSNE进行数据降维并绘制聚类可视化结果**

   ```python
   def tsne_plot(data_zs,r,show_flag=False):
   	if show_flag:
   		# 使用TSNE进行数据降纬并展示聚类结果
   		from sklearn.manifold import TSNE
   		tsne = TSNE()
   		# 进行降维
   		tsne.fit_transform(data_zs)
   		# 转换数据格式
   		tsne = pd.DataFrame(tsne.embedding_,index=data_zs.index)
           print(tsne)
   		# 把不同类别用不同颜色和样式绘制
   		import matplotlib.pyplot as plt
   		d = tsne[r[u'聚类类别'] == 0]
   		plt.plot(d[0],d[1],'r.')
   		d = tsne[r[u'聚类类别'] == 1]
   		plt.plot(d[0],d[1],'go')
   		d = tsne[r[u'聚类类别'] == 2]
   		plt.plot(d[0],d[1],'b*')
   		plt.show()
   ```

   很多时候聚类的数据都是3维及以上的，并不能直观的绘图，所以需要用TSNE()降维再绘图

   - 降维

     ```python
     from sklearn.manifold import TSNE
     tsne = TSNE()
     # 进行降维
     tsne.fit_transform(data_zs)
     # 转换数据格式
     tsne = pd.DataFrame(tsne.embedding_,index=data_zs.index)
     print(tsne)
     ```

     结果：

     ```
                  0          1
     Id                       
     1    26.496473   0.467441
     2   -12.278794 -25.287786
     3     3.451262  29.837729
     4    10.840672  26.657825
     5   -14.160274 -11.983387
     6    23.714819  -3.791951
     7    12.535678 -29.901342
     8     3.351410  -6.982276
     9    22.311295  -0.055775
     ..         ...        ...
     933 -13.625098 -10.518986
     934 -25.674400  24.570143
     935 -19.019663  -2.581036
     936 -28.532398  15.450959
     937 -16.267090 -24.325630
     938   3.244879 -14.367769
     939   5.331686 -23.553940
     940  -0.298702  -0.094416
     941   6.043116  -6.003988
     942  12.865389 -13.507012
     
     [940 rows x 2 columns]
     ```

   - 降维可视化

     ![](https://ws4.sinaimg.cn/large/0069RVTdgy1fubpikxhdej30hs0dcmy0.jpg)

2. 聚类分析算法评价

   对于聚类算法，我们一般从下面三个角度去评价，这里直接截取书上的截图

   ![](https://ws4.sinaimg.cn/large/0069RVTdgy1fubplngikjj30li0fbn2d.jpg)

   